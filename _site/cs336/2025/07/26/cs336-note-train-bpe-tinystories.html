<!DOCTYPE html>
<html lang="en"><head>
  <link rel="shortcut icon" type="image/png" href="/assets/favicon.png">
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Study Notes: Stanford CS336 Language Modeling from Scratch [3] | üçí Han‚Äôs Generative AI Quest</title>
<meta name="generator" content="Jekyll v4.3.2" />
<meta property="og:title" content="Study Notes: Stanford CS336 Language Modeling from Scratch [3]" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Building a BPE Tokenizer from Scratch: Train the Tokenizer using TinyStories Dataset" />
<meta property="og:description" content="Building a BPE Tokenizer from Scratch: Train the Tokenizer using TinyStories Dataset" />
<link rel="canonical" href="http://localhost:4000/cs336/2025/07/26/cs336-note-train-bpe-tinystories.html" />
<meta property="og:url" content="http://localhost:4000/cs336/2025/07/26/cs336-note-train-bpe-tinystories.html" />
<meta property="og:site_name" content="üçí Han‚Äôs Generative AI Quest" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2025-07-26T00:00:00-07:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Study Notes: Stanford CS336 Language Modeling from Scratch [3]" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2025-07-26T00:00:00-07:00","datePublished":"2025-07-26T00:00:00-07:00","description":"Building a BPE Tokenizer from Scratch: Train the Tokenizer using TinyStories Dataset","headline":"Study Notes: Stanford CS336 Language Modeling from Scratch [3]","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/cs336/2025/07/26/cs336-note-train-bpe-tinystories.html"},"url":"http://localhost:4000/cs336/2025/07/26/cs336-note-train-bpe-tinystories.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="üçí Han&apos;s Generative AI Quest" />

<!-- MathJax Configuration -->
<script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      displayMath: [['$$', '$$'], ['\\[', '\\]']],
      processEscapes: true,
      processEnvironments: true
    },
    options: {
      skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
    }
  };
</script>

<script type="text/javascript" id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/">üçí Han&#39;s Generative AI Quest</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">About</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Study Notes: Stanford CS336 Language Modeling from Scratch [3]</h1>
    <p class="post-meta"><time class="dt-published" datetime="2025-07-26T00:00:00-07:00" itemprop="datePublished">
        Jul 26, 2025
      </time>‚Ä¢ 
          <span itemprop="author" itemscope itemtype="http://schema.org/Person">
            <span class="p-author h-card" itemprop="name">Han Yu</span></span></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <h1 id="building-a-bpe-tokenizer-from-scratch-train-the-tokenizer-using-tinystories-dataset">Building a BPE Tokenizer from Scratch: Train the Tokenizer using TinyStories Dataset</h1>

<p>Ever wondered how modern language models like GPT break down text into tokens? In this note, I will share how to build a Byte Pair Encoding (BPE) tokenizer from scratch and train it on the <a href="https://arxiv.org/abs/2305.07759">TinyStories Dataset</a>. We will see how BPE achieves impressive compression ratios.</p>

<h2 id="what-is-bpe-tokenization">What is BPE Tokenization?</h2>

<p>Byte Pair Encoding (BPE) is a compression algorithm that‚Äôs become the backbone of modern tokenization. Here‚Äôs how it works:</p>

<ol>
  <li><strong>Start with bytes</strong>: Every character becomes its byte representation (0-255)</li>
  <li><strong>Find frequent pairs</strong>: Look for the most common pair of adjacent tokens</li>
  <li><strong>Merge and repeat</strong>: Replace the most frequent pair with a new token, then repeat</li>
</ol>

<h3 id="a-simple-example">A Simple Example</h3>

<p>Let‚Äôs say we have the word ‚Äúhello‚Äù appearing many times in our text:</p>
<ul>
  <li>Initially: <code class="language-plaintext highlighter-rouge">h-e-l-l-o</code> (5 tokens)</li>
  <li>If ‚Äúl-l‚Äù is the most frequent pair, merge it: <code class="language-plaintext highlighter-rouge">h-e-ll-o</code> (4 tokens)</li>
  <li>If ‚Äúe-ll‚Äù becomes frequent, merge it: <code class="language-plaintext highlighter-rouge">h-ell-o</code> (3 tokens)</li>
</ul>

<p>This process creates a vocabulary that efficiently represents common patterns in your text. Check out <a href="https://bearbearyu1223.github.io/cs336/2025/07/22/cs336-note-simple-bpe.html">my previous post</a> for a brief introduction.</p>

<h2 id="the-tinystories-dataset">The TinyStories Dataset</h2>

<p>We‚Äôll train our tokenizer on <a href="https://arxiv.org/abs/2305.07759">TinyStories</a>, a fascinating dataset of short stories written using only words that 3-4 year olds typically understand. These stories were generated by GPT-3.5 and GPT-4, making them perfect for experimenting with tokenization.</p>

<h3 id="downloading-the-data">Downloading the Data</h3>

<p>First, let‚Äôs download the TinyStories froom Huggingface:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="err">!</span><span class="n">mkdir</span> <span class="o">-</span><span class="n">p</span> <span class="n">data</span>
<span class="err">!</span><span class="n">cd</span> <span class="n">data</span>

<span class="err">!</span><span class="n">wget</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">huggingface</span><span class="p">.</span><span class="n">co</span><span class="o">/</span><span class="n">datasets</span><span class="o">/</span><span class="n">roneneldan</span><span class="o">/</span><span class="n">TinyStories</span><span class="o">/</span><span class="n">resolve</span><span class="o">/</span><span class="n">main</span><span class="o">/</span><span class="n">TinyStoriesV2</span><span class="o">-</span><span class="n">GPT4</span><span class="o">-</span><span class="n">train</span><span class="p">.</span><span class="n">txt</span>
<span class="err">!</span><span class="n">wget</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">huggingface</span><span class="p">.</span><span class="n">co</span><span class="o">/</span><span class="n">datasets</span><span class="o">/</span><span class="n">roneneldan</span><span class="o">/</span><span class="n">TinyStories</span><span class="o">/</span><span class="n">resolve</span><span class="o">/</span><span class="n">main</span><span class="o">/</span><span class="n">TinyStoriesV2</span><span class="o">-</span><span class="n">GPT4</span><span class="o">-</span><span class="n">valid</span><span class="p">.</span><span class="n">txt</span>

<span class="err">!</span><span class="n">wget</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">huggingface</span><span class="p">.</span><span class="n">co</span><span class="o">/</span><span class="n">datasets</span><span class="o">/</span><span class="n">stanford</span><span class="o">-</span><span class="n">cs336</span><span class="o">/</span><span class="n">owt</span><span class="o">-</span><span class="n">sample</span><span class="o">/</span><span class="n">resolve</span><span class="o">/</span><span class="n">main</span><span class="o">/</span><span class="n">owt_train</span><span class="p">.</span><span class="n">txt</span><span class="p">.</span><span class="n">gz</span>
<span class="err">!</span><span class="n">gunzip</span> <span class="n">owt_train</span><span class="p">.</span><span class="n">txt</span><span class="p">.</span><span class="n">gz</span>
<span class="err">!</span><span class="n">wget</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">huggingface</span><span class="p">.</span><span class="n">co</span><span class="o">/</span><span class="n">datasets</span><span class="o">/</span><span class="n">stanford</span><span class="o">-</span><span class="n">cs336</span><span class="o">/</span><span class="n">owt</span><span class="o">-</span><span class="n">sample</span><span class="o">/</span><span class="n">resolve</span><span class="o">/</span><span class="n">main</span><span class="o">/</span><span class="n">owt_valid</span><span class="p">.</span><span class="n">txt</span><span class="p">.</span><span class="n">gz</span>
<span class="err">!</span><span class="n">gunzip</span> <span class="n">owt_valid</span><span class="p">.</span><span class="n">txt</span><span class="p">.</span><span class="n">gz</span>

<span class="err">!</span><span class="n">cd</span> <span class="p">..</span>
</code></pre></div></div>

<h2 id="challenge-parallelizing-pre-tokenization">Challenge: Parallelizing Pre-tokenization</h2>

<p>The TinyStories dataset is big (over 2GB), which presents a challenge for tokenizer training. We need to:</p>
<ol>
  <li>Process the file in parallel for speed</li>
  <li>Ensure we don‚Äôt split tokens incorrectly at chunk boundaries</li>
</ol>

<h3 id="solution-smart-chunking-with-special-tokens">Solution: Smart Chunking with Special Tokens</h3>

<p>Our solution uses special tokens (like <code class="language-plaintext highlighter-rouge">&lt;|endoftext|&gt;</code>) as natural boundaries for splitting the file.</p>

<p><strong>Simple Example</strong>: Let‚Äôs say we have a text file containing: ‚ÄúHello<code class="language-plaintext highlighter-rouge">&lt;SPLIT&gt;</code>World<code class="language-plaintext highlighter-rouge">&lt;SPLIT&gt;</code>How<code class="language-plaintext highlighter-rouge">&lt;SPLIT&gt;</code>Are<code class="language-plaintext highlighter-rouge">&lt;SPLIT&gt;</code>You‚Äù, special split token is <code class="language-plaintext highlighter-rouge">&lt;SPLIT&gt;</code>, and we want to divide the text into 3 chunks.</p>

<p>Here‚Äôs one implementation for intelligent file chunking as shared in the <a href="https://github.com/stanford-cs336/assignment1-basics/blob/main/cs336_basics/pretokenization_example.py">cs336 lecture notes</a>:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">BinaryIO</span>

<span class="k">def</span> <span class="nf">find_chunk_boundaries</span><span class="p">(</span> <span class="nb">file</span><span class="p">:</span> <span class="n">BinaryIO</span><span class="p">,</span>
      <span class="n">desired_num_chunks</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
      <span class="n">split_special_token</span><span class="p">:</span> <span class="nb">bytes</span><span class="p">)</span><span class="o">-&gt;</span><span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">]:</span>
  <span class="s">"""
  Chunk the file into parts that can be counted independently.
  May return fewer chunks if the boundaries end up overlapping.
  """</span>
  <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">split_special_token</span><span class="p">,</span> <span class="nb">bytes</span><span class="p">),(</span>
      <span class="s">"Must represent special token as a bytestring"</span>
  <span class="p">)</span>

  <span class="c1"># Get total file size in bytes
</span>  <span class="nb">file</span><span class="p">.</span><span class="n">seek</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">os</span><span class="p">.</span><span class="n">SEEK_END</span><span class="p">)</span>
  <span class="n">file_size</span> <span class="o">=</span> <span class="nb">file</span><span class="p">.</span><span class="n">tell</span><span class="p">()</span>
  <span class="nb">file</span><span class="p">.</span><span class="n">seek</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

  <span class="n">chunk_size</span> <span class="o">=</span> <span class="n">file_size</span> <span class="o">//</span> <span class="n">desired_num_chunks</span>

  <span class="c1"># Initial guesses for chunk boundary locations, uniformly spaced
</span>  <span class="c1"># Chunks start on previous index, don't include last index
</span>  <span class="n">chunk_boundaries</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="n">chunk_size</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">desired_num_chunks</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)]</span>
  <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Initial guess of the chunk boundaries: </span><span class="si">{</span><span class="n">chunk_boundaries</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
  <span class="n">chunk_boundaries</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">file_size</span>

  <span class="n">mini_chunk_size</span> <span class="o">=</span> <span class="mi">4096</span>  <span class="c1"># Read ahead by 4k bytes at a time
</span>
  <span class="k">for</span> <span class="n">bi</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">chunk_boundaries</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
      <span class="n">initial_position</span> <span class="o">=</span> <span class="n">chunk_boundaries</span><span class="p">[</span><span class="n">bi</span><span class="p">]</span>
      <span class="nb">file</span><span class="p">.</span><span class="n">seek</span><span class="p">(</span><span class="n">initial_position</span><span class="p">)</span>  <span class="c1"># Start at boundary guess
</span>      <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
          <span class="n">mini_chunk</span> <span class="o">=</span> <span class="nb">file</span><span class="p">.</span><span class="n">read</span><span class="p">(</span><span class="n">mini_chunk_size</span><span class="p">)</span>  <span class="c1"># Read a mini chunk
</span>
          <span class="c1"># If EOF, this boundary should be at the end of the file
</span>          <span class="k">if</span> <span class="n">mini_chunk</span> <span class="o">==</span> <span class="sa">b</span><span class="s">""</span><span class="p">:</span>
              <span class="n">chunk_boundaries</span><span class="p">[</span><span class="n">bi</span><span class="p">]</span> <span class="o">=</span> <span class="n">file_size</span>
              <span class="k">break</span>

          <span class="c1"># Find the special token in the mini chunk
</span>          <span class="n">found_at</span> <span class="o">=</span> <span class="n">mini_chunk</span><span class="p">.</span><span class="n">find</span><span class="p">(</span><span class="n">split_special_token</span><span class="p">)</span>
          <span class="k">if</span> <span class="n">found_at</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
              <span class="n">chunk_boundaries</span><span class="p">[</span><span class="n">bi</span><span class="p">]</span> <span class="o">=</span> <span class="n">initial_position</span> <span class="o">+</span> <span class="n">found_at</span>
              <span class="k">break</span>
          <span class="n">initial_position</span> <span class="o">+=</span> <span class="n">mini_chunk_size</span>

  <span class="c1"># Make sure all boundaries are unique, but might be fewer than desired_num_chunks
</span>  <span class="k">return</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">chunk_boundaries</span><span class="p">))</span>
</code></pre></div></div>

<h3 id="testing-our-chunking-algorithm">Testing Our Chunking Algorithm</h3>

<p>Let‚Äôs see how this works with a concrete example:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">io</span>
<span class="k">def</span> <span class="nf">demonstrate_chunk_boundaries</span><span class="p">():</span>
    <span class="s">"""Demonstrate how to use find_chunk_boundaries with a practical example."""</span>

    <span class="c1"># Create sample data - our example text
</span>    <span class="n">sample_text</span> <span class="o">=</span> <span class="s">"Hello&lt;SPLIT&gt;World&lt;SPLIT&gt;How&lt;SPLIT&gt;Are&lt;SPLIT&gt;You"</span>
    <span class="n">sample_bytes</span> <span class="o">=</span> <span class="n">sample_text</span><span class="p">.</span><span class="n">encode</span><span class="p">(</span><span class="s">'utf-8'</span><span class="p">)</span>

    <span class="k">print</span><span class="p">(</span><span class="s">"=== Original Data ==="</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Text: </span><span class="si">{</span><span class="n">sample_text</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Bytes: </span><span class="si">{</span><span class="n">sample_bytes</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Total size: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">sample_bytes</span><span class="p">)</span><span class="si">}</span><span class="s"> bytes"</span><span class="p">)</span>
    <span class="k">print</span><span class="p">()</span>

    <span class="c1"># Create a file-like object from our sample data
</span>    <span class="n">file_obj</span> <span class="o">=</span> <span class="n">io</span><span class="p">.</span><span class="n">BytesIO</span><span class="p">(</span><span class="n">sample_bytes</span><span class="p">)</span>

    <span class="c1"># Define our split token
</span>    <span class="n">split_token</span> <span class="o">=</span> <span class="sa">b</span><span class="s">"&lt;SPLIT&gt;"</span>
    <span class="n">desired_chunks</span> <span class="o">=</span> <span class="mi">3</span>

    <span class="k">print</span><span class="p">(</span><span class="s">"=== Finding Chunk Boundaries ==="</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Desired number of chunks: </span><span class="si">{</span><span class="n">desired_chunks</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Split token: </span><span class="si">{</span><span class="n">split_token</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
    <span class="k">print</span><span class="p">()</span>

    <span class="c1"># Find the chunk boundaries
</span>    <span class="n">boundaries</span> <span class="o">=</span> <span class="n">find_chunk_boundaries</span><span class="p">(</span><span class="n">file_obj</span><span class="p">,</span> <span class="n">desired_chunks</span><span class="p">,</span> <span class="n">split_token</span><span class="p">)</span>

    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Final boundaries: </span><span class="si">{</span><span class="n">boundaries</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Number of chunks created: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">boundaries</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
    <span class="k">print</span><span class="p">()</span>

    <span class="c1"># Demonstrate how to use the boundaries to read chunks
</span>    <span class="k">print</span><span class="p">(</span><span class="s">"=== Reading Chunks ==="</span><span class="p">)</span>
    <span class="n">file_obj</span><span class="p">.</span><span class="n">seek</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># Reset file pointer
</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">boundaries</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">start_pos</span> <span class="o">=</span> <span class="n">boundaries</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">end_pos</span> <span class="o">=</span> <span class="n">boundaries</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>
        <span class="n">chunk_size</span> <span class="o">=</span> <span class="n">end_pos</span> <span class="o">-</span> <span class="n">start_pos</span>

        <span class="c1"># Read the chunk
</span>        <span class="n">file_obj</span><span class="p">.</span><span class="n">seek</span><span class="p">(</span><span class="n">start_pos</span><span class="p">)</span>
        <span class="n">chunk_data</span> <span class="o">=</span> <span class="n">file_obj</span><span class="p">.</span><span class="n">read</span><span class="p">(</span><span class="n">chunk_size</span><span class="p">)</span>
        <span class="n">chunk_text</span> <span class="o">=</span> <span class="n">chunk_data</span><span class="p">.</span><span class="n">decode</span><span class="p">(</span><span class="s">'utf-8'</span><span class="p">)</span>

        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Chunk </span><span class="si">{</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="si">}</span><span class="s">:"</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"  Position: bytes </span><span class="si">{</span><span class="n">start_pos</span><span class="si">}</span><span class="s">-</span><span class="si">{</span><span class="n">end_pos</span><span class="o">-</span><span class="mi">1</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"  Size: </span><span class="si">{</span><span class="n">chunk_size</span><span class="si">}</span><span class="s"> bytes"</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"  Content: '</span><span class="si">{</span><span class="n">chunk_text</span><span class="si">}</span><span class="s">'"</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"  Raw bytes: </span><span class="si">{</span><span class="n">chunk_data</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
        <span class="k">print</span><span class="p">()</span>
</code></pre></div></div>

<p>Running this demonstration:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">demonstrate_chunk_boundaries</span><span class="p">()</span>
</code></pre></div></div>

<p><strong>Output:</strong></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>=== Original Data ===
Text: Hello&lt;SPLIT&gt;World&lt;SPLIT&gt;How&lt;SPLIT&gt;Are&lt;SPLIT&gt;You
Bytes: b'Hello&lt;SPLIT&gt;World&lt;SPLIT&gt;How&lt;SPLIT&gt;Are&lt;SPLIT&gt;You'
Total size: 47 bytes

=== Finding Chunk Boundaries ===
Desired number of chunks: 3
Split token: b'&lt;SPLIT&gt;'

Initial guess of the chunk boundaries: [0, 15, 30, 45]
Final boundaries: [0, 17, 37, 47]
Number of chunks created: 3

=== Reading Chunks ===
Chunk 1:
  Position: bytes 0-16
  Size: 17 bytes
  Content: 'Hello&lt;SPLIT&gt;World'
  Raw bytes: b'Hello&lt;SPLIT&gt;World'

Chunk 2:
  Position: bytes 17-36
  Size: 20 bytes
  Content: '&lt;SPLIT&gt;How&lt;SPLIT&gt;Are'
  Raw bytes: b'&lt;SPLIT&gt;How&lt;SPLIT&gt;Are'

Chunk 3:
  Position: bytes 37-46
  Size: 10 bytes
  Content: '&lt;SPLIT&gt;You'
  Raw bytes: b'&lt;SPLIT&gt;You'
</code></pre></div></div>

<p>Notice how the algorithm automatically adjusted the boundaries to align with <code class="language-plaintext highlighter-rouge">&lt;SPLIT&gt;</code> tokens, ensuring clean chunk separation.</p>

<h2 id="bpe-training-implementation">BPE Training Implementation</h2>

<p>Now implement the core BPE training algorithm. The implementation shared here handles parallel processing, special tokens, and efficient pair counting.</p>

<h3 id="core-training-function">Core Training Function</h3>

<p>Here‚Äôs is my complete BPE training implementation:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">multiprocessing</span> <span class="k">as</span> <span class="n">mp</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">defaultdict</span><span class="p">,</span> <span class="n">Counter</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">BinaryIO</span>

<span class="c1"># Simplified GPT-2-style regex pattern for pre-tokenization (using standard re module)
</span><span class="n">GPT2_SPLIT_PATTERN</span> <span class="o">=</span> <span class="sa">r</span><span class="s">"""'(?:[sdmt]|ll|ve|re)| ?[a-zA-Z√Ä-√ø]+| ?[0-9]+| ?[^\s\w]+|\s+(?!\S)|\s+"""</span>

<span class="k">def</span> <span class="nf">process_chunk</span><span class="p">(</span><span class="n">args</span><span class="p">):</span>
    <span class="s">"""Process a chunk of the file and return word counts."""</span>
    <span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">input_path</span><span class="p">,</span> <span class="n">special_tokens</span> <span class="o">=</span> <span class="n">args</span>
    <span class="n">word_counts</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>

    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">input_path</span><span class="p">,</span> <span class="s">'rb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">f</span><span class="p">.</span><span class="n">seek</span><span class="p">(</span><span class="n">start</span><span class="p">)</span>
        <span class="n">chunk</span> <span class="o">=</span> <span class="n">f</span><span class="p">.</span><span class="n">read</span><span class="p">(</span><span class="n">end</span> <span class="o">-</span> <span class="n">start</span><span class="p">).</span><span class="n">decode</span><span class="p">(</span><span class="s">'utf-8'</span><span class="p">,</span> <span class="n">errors</span><span class="o">=</span><span class="s">'ignore'</span><span class="p">)</span>

        <span class="c1"># Split on special tokens to prevent merging across boundaries
</span>        <span class="k">if</span> <span class="n">special_tokens</span><span class="p">:</span>
            <span class="n">pattern</span> <span class="o">=</span> <span class="s">'|'</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">re</span><span class="p">.</span><span class="n">escape</span><span class="p">(</span><span class="n">token</span><span class="p">)</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">special_tokens</span><span class="p">)</span>
            <span class="n">text_segments</span> <span class="o">=</span> <span class="n">re</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="sa">f</span><span class="s">'(</span><span class="si">{</span><span class="n">pattern</span><span class="si">}</span><span class="s">)'</span><span class="p">,</span> <span class="n">chunk</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">text_segments</span> <span class="o">=</span> <span class="p">[</span><span class="n">chunk</span><span class="p">]</span>

        <span class="k">for</span> <span class="n">segment</span> <span class="ow">in</span> <span class="n">text_segments</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">segment</span> <span class="ow">in</span> <span class="n">special_tokens</span><span class="p">:</span>
                <span class="k">continue</span>  <span class="c1"># Skip special tokens during counting
</span>
            <span class="c1"># Apply GPT-2 regex pattern
</span>            <span class="k">for</span> <span class="n">match</span> <span class="ow">in</span> <span class="n">re</span><span class="p">.</span><span class="n">finditer</span><span class="p">(</span><span class="n">GPT2_SPLIT_PATTERN</span><span class="p">,</span> <span class="n">segment</span><span class="p">):</span>
                <span class="n">token_text</span> <span class="o">=</span> <span class="n">match</span><span class="p">.</span><span class="n">group</span><span class="p">()</span>
                <span class="n">token_bytes</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">token_text</span><span class="p">.</span><span class="n">encode</span><span class="p">(</span><span class="s">'utf-8'</span><span class="p">))</span>
                <span class="n">word_counts</span><span class="p">[</span><span class="n">token_bytes</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="k">return</span> <span class="n">word_counts</span>


<span class="k">def</span> <span class="nf">train_bpe_tokenizer</span><span class="p">(</span><span class="n">input_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">special_tokens</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">bytes</span><span class="p">],</span> <span class="nb">list</span><span class="p">[</span><span class="nb">tuple</span><span class="p">[</span><span class="nb">bytes</span><span class="p">,</span> <span class="nb">bytes</span><span class="p">]]]:</span>
    <span class="s">"""
    Train a byte-level Byte Pair Encoding (BPE) tokenizer from a text file.

    Args:
        input_path: Path to the input text file containing training data
        vocab_size: Maximum size of the final vocabulary (includes initial bytes + special tokens + merges)
        special_tokens: List of special token strings to include in vocabulary
        verbose: Whether to print training progress information

    Returns:
        vocab: Complete tokenizer vocabulary mapping token IDs to byte sequences
        merges: Ordered list of BPE merge operations performed during training
    """</span>
    <span class="kn">import</span> <span class="nn">time</span>

    <span class="c1"># Initialize vocabulary with bytes 0-255
</span>    <span class="n">vocab</span> <span class="o">=</span> <span class="p">{</span><span class="n">i</span><span class="p">:</span> <span class="nb">bytes</span><span class="p">([</span><span class="n">i</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">256</span><span class="p">)}</span>
    <span class="n">next_id</span> <span class="o">=</span> <span class="mi">256</span>

    <span class="c1"># Add special tokens to vocabulary
</span>    <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">special_tokens</span><span class="p">:</span>
        <span class="n">token_bytes</span> <span class="o">=</span> <span class="n">token</span><span class="p">.</span><span class="n">encode</span><span class="p">(</span><span class="s">'utf-8'</span><span class="p">)</span>
        <span class="n">vocab</span><span class="p">[</span><span class="n">next_id</span><span class="p">]</span> <span class="o">=</span> <span class="n">token_bytes</span>
        <span class="n">next_id</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="s">"Step 1: Setting up parallel processing..."</span><span class="p">)</span>

    <span class="c1"># Get chunk boundaries for multiprocessing
</span>    <span class="n">num_processes</span> <span class="o">=</span> <span class="n">mp</span><span class="p">.</span><span class="n">cpu_count</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Using </span><span class="si">{</span><span class="n">num_processes</span><span class="si">}</span><span class="s"> processes for parallel tokenization"</span><span class="p">)</span>

    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">input_path</span><span class="p">,</span> <span class="s">'rb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">special_tokens</span><span class="p">:</span>
            <span class="c1"># Use first special token for chunking boundaries
</span>            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Finding chunk boundaries aligned with special token: </span><span class="si">{</span><span class="n">special_tokens</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
            <span class="n">boundaries</span> <span class="o">=</span> <span class="n">find_chunk_boundaries</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">num_processes</span><span class="p">,</span> <span class="n">special_tokens</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">encode</span><span class="p">(</span><span class="s">'utf-8'</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Use simple chunking without special token alignment
</span>            <span class="n">f</span><span class="p">.</span><span class="n">seek</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">os</span><span class="p">.</span><span class="n">SEEK_END</span><span class="p">)</span>
            <span class="n">file_size</span> <span class="o">=</span> <span class="n">f</span><span class="p">.</span><span class="n">tell</span><span class="p">()</span>
            <span class="n">chunk_size</span> <span class="o">=</span> <span class="n">file_size</span> <span class="o">//</span> <span class="n">num_processes</span>
            <span class="n">boundaries</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="n">chunk_size</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_processes</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)]</span>
            <span class="n">boundaries</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">file_size</span>
            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"File size: </span><span class="si">{</span><span class="n">file_size</span><span class="si">:</span><span class="p">,</span><span class="si">}</span><span class="s"> bytes, chunk size: </span><span class="si">{</span><span class="n">chunk_size</span><span class="si">:</span><span class="p">,</span><span class="si">}</span><span class="s"> bytes"</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Created </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">boundaries</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="si">}</span><span class="s"> chunks for processing"</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s">Step 2: Pre-tokenizing text corpus..."</span><span class="p">)</span>

    <span class="c1"># Process chunks in parallel
</span>    <span class="n">chunk_args</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">start</span><span class="p">,</span> <span class="n">end</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">boundaries</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">boundaries</span><span class="p">[</span><span class="mi">1</span><span class="p">:]):</span>
        <span class="n">chunk_args</span><span class="p">.</span><span class="n">append</span><span class="p">((</span><span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">input_path</span><span class="p">,</span> <span class="n">special_tokens</span><span class="p">))</span>

    <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="n">time</span><span class="p">()</span>
    <span class="k">with</span> <span class="n">mp</span><span class="p">.</span><span class="n">Pool</span><span class="p">(</span><span class="n">processes</span><span class="o">=</span><span class="n">num_processes</span><span class="p">)</span> <span class="k">as</span> <span class="n">pool</span><span class="p">:</span>
        <span class="n">chunk_results</span> <span class="o">=</span> <span class="n">pool</span><span class="p">.</span><span class="nb">map</span><span class="p">(</span><span class="n">process_chunk</span><span class="p">,</span> <span class="n">chunk_args</span><span class="p">)</span>
    <span class="n">tokenization_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span>

    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Pre-tokenization completed in </span><span class="si">{</span><span class="n">tokenization_time</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s"> seconds"</span><span class="p">)</span>

    <span class="c1"># Merge results from all chunks
</span>    <span class="n">word_counts</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
    <span class="n">total_tokens</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">chunk_result</span> <span class="ow">in</span> <span class="n">chunk_results</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">count</span> <span class="ow">in</span> <span class="n">chunk_result</span><span class="p">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">word_counts</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">+=</span> <span class="n">count</span>
            <span class="n">total_tokens</span> <span class="o">+=</span> <span class="n">count</span>

    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Found </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">word_counts</span><span class="p">)</span><span class="si">:</span><span class="p">,</span><span class="si">}</span><span class="s"> unique word types"</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Total token count: </span><span class="si">{</span><span class="n">total_tokens</span><span class="si">:</span><span class="p">,</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Most common words:"</span><span class="p">)</span>
        <span class="n">sorted_words</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">word_counts</span><span class="p">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">word_bytes</span><span class="p">,</span> <span class="n">count</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">sorted_words</span><span class="p">[:</span><span class="mi">5</span><span class="p">]):</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">word_str</span> <span class="o">=</span> <span class="nb">bytes</span><span class="p">(</span><span class="n">word_bytes</span><span class="p">).</span><span class="n">decode</span><span class="p">(</span><span class="s">'utf-8'</span><span class="p">,</span> <span class="n">errors</span><span class="o">=</span><span class="s">'replace'</span><span class="p">)</span>
                <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"  </span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s">. '</span><span class="si">{</span><span class="n">word_str</span><span class="si">}</span><span class="s">' -&gt; </span><span class="si">{</span><span class="n">count</span><span class="si">:</span><span class="p">,</span><span class="si">}</span><span class="s"> times"</span><span class="p">)</span>
            <span class="k">except</span><span class="p">:</span>
                <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"  </span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s">. </span><span class="si">{</span><span class="n">word_bytes</span><span class="si">}</span><span class="s"> -&gt; </span><span class="si">{</span><span class="n">count</span><span class="si">:</span><span class="p">,</span><span class="si">}</span><span class="s"> times"</span><span class="p">)</span>

    <span class="c1"># Convert to working format for BPE (list of byte values)
</span>    <span class="n">word_freq</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">word_bytes</span><span class="p">,</span> <span class="n">freq</span> <span class="ow">in</span> <span class="n">word_counts</span><span class="p">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">word_tokens</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">word_bytes</span><span class="p">)</span>  <span class="c1"># Convert to list of ints
</span>        <span class="n">word_freq</span><span class="p">[</span><span class="nb">tuple</span><span class="p">(</span><span class="n">word_tokens</span><span class="p">)]</span> <span class="o">=</span> <span class="n">freq</span>

    <span class="n">merges</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">pair_index</span> <span class="o">=</span> <span class="p">{}</span>  <span class="c1"># Efficient indexing for pair counting
</span>
    <span class="k">def</span> <span class="nf">update_pair_index</span><span class="p">(</span><span class="n">word_freq</span><span class="p">,</span> <span class="n">pair_index</span><span class="p">):</span>
        <span class="s">"""Update the pair index for efficient counting."""</span>
        <span class="n">pair_index</span><span class="p">.</span><span class="n">clear</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">freq</span> <span class="ow">in</span> <span class="n">word_freq</span><span class="p">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">word</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
                <span class="n">pair</span> <span class="o">=</span> <span class="p">(</span><span class="n">word</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">word</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">])</span>
                <span class="k">if</span> <span class="n">pair</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">pair_index</span><span class="p">:</span>
                    <span class="n">pair_index</span><span class="p">[</span><span class="n">pair</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="n">pair_index</span><span class="p">[</span><span class="n">pair</span><span class="p">].</span><span class="n">append</span><span class="p">((</span><span class="n">word</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">freq</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">count_pairs</span><span class="p">(</span><span class="n">pair_index</span><span class="p">):</span>
        <span class="s">"""Count pair frequencies efficiently using the index."""</span>
        <span class="n">pair_counts</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">pair</span><span class="p">,</span> <span class="n">occurrences</span> <span class="ow">in</span> <span class="n">pair_index</span><span class="p">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">total_count</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">freq</span> <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">freq</span> <span class="ow">in</span> <span class="n">occurrences</span><span class="p">)</span>
            <span class="n">pair_counts</span><span class="p">[</span><span class="n">pair</span><span class="p">]</span> <span class="o">=</span> <span class="n">total_count</span>
        <span class="k">return</span> <span class="n">pair_counts</span>

    <span class="c1"># BPE training loop
</span>    <span class="n">target_merges</span> <span class="o">=</span> <span class="n">vocab_size</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"</span><span class="se">\n</span><span class="s">Step 3: Training BPE with </span><span class="si">{</span><span class="n">target_merges</span><span class="si">:</span><span class="p">,</span><span class="si">}</span><span class="s"> merges..."</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Initial vocabulary size: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">)</span><span class="si">}</span><span class="s"> (256 bytes + </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">special_tokens</span><span class="p">)</span><span class="si">}</span><span class="s"> special tokens)"</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s">"="</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>

    <span class="n">bpe_start_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="n">time</span><span class="p">()</span>

    <span class="k">for</span> <span class="n">merge_num</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">target_merges</span><span class="p">):</span>
        <span class="n">merge_step_start</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="n">time</span><span class="p">()</span>

        <span class="c1"># Update pair index
</span>        <span class="n">update_pair_index</span><span class="p">(</span><span class="n">word_freq</span><span class="p">,</span> <span class="n">pair_index</span><span class="p">)</span>

        <span class="c1"># Count pairs efficiently
</span>        <span class="n">pair_counts</span> <span class="o">=</span> <span class="n">count_pairs</span><span class="p">(</span><span class="n">pair_index</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">pair_counts</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"No more pairs to merge at step </span><span class="si">{</span><span class="n">merge_num</span> <span class="o">+</span> <span class="mi">1</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
            <span class="k">break</span>

        <span class="c1"># Find most frequent pair (with lexicographic tiebreaking)
</span>        <span class="n">best_pair</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">pair_counts</span><span class="p">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]))[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">best_count</span> <span class="o">=</span> <span class="n">pair_counts</span><span class="p">[</span><span class="n">best_pair</span><span class="p">]</span>

        <span class="c1"># Create new token for merge
</span>        <span class="n">new_token_id</span> <span class="o">=</span> <span class="n">next_id</span>
        <span class="n">next_id</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="c1"># Get the byte sequences for the tokens being merged
</span>        <span class="n">left_bytes</span> <span class="o">=</span> <span class="n">vocab</span><span class="p">[</span><span class="n">best_pair</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
        <span class="n">right_bytes</span> <span class="o">=</span> <span class="n">vocab</span><span class="p">[</span><span class="n">best_pair</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span>

        <span class="c1"># Record merge as byte sequences
</span>        <span class="n">merges</span><span class="p">.</span><span class="n">append</span><span class="p">((</span><span class="n">left_bytes</span><span class="p">,</span> <span class="n">right_bytes</span><span class="p">))</span>

        <span class="c1"># Update vocabulary - merge the two byte sequences
</span>        <span class="n">vocab</span><span class="p">[</span><span class="n">new_token_id</span><span class="p">]</span> <span class="o">=</span> <span class="n">left_bytes</span> <span class="o">+</span> <span class="n">right_bytes</span>

        <span class="c1"># Update word frequencies by applying merge
</span>        <span class="n">new_word_freq</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">freq</span> <span class="ow">in</span> <span class="n">word_freq</span><span class="p">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">new_word</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">while</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">word</span><span class="p">):</span>
                <span class="k">if</span> <span class="p">(</span><span class="n">i</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">word</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span> <span class="ow">and</span>
                    <span class="n">word</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="n">best_pair</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">and</span>
                    <span class="n">word</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">best_pair</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
                    <span class="n">new_word</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">new_token_id</span><span class="p">)</span>
                    <span class="n">i</span> <span class="o">+=</span> <span class="mi">2</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">new_word</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">word</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
                    <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>

            <span class="n">new_word_tuple</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">new_word</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">new_word_tuple</span> <span class="ow">in</span> <span class="n">new_word_freq</span><span class="p">:</span>
                <span class="n">new_word_freq</span><span class="p">[</span><span class="n">new_word_tuple</span><span class="p">]</span> <span class="o">+=</span> <span class="n">freq</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">new_word_freq</span><span class="p">[</span><span class="n">new_word_tuple</span><span class="p">]</span> <span class="o">=</span> <span class="n">freq</span>

        <span class="n">word_freq</span> <span class="o">=</span> <span class="n">new_word_freq</span>
        <span class="n">merge_step_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">merge_step_start</span>

        <span class="c1"># Progress logging
</span>        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">merge_num</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">merge_num</span> <span class="o">&lt;</span> <span class="mi">10</span> <span class="ow">or</span> <span class="p">(</span><span class="n">merge_num</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="mi">1000</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">left_str</span> <span class="o">=</span> <span class="n">left_bytes</span><span class="p">.</span><span class="n">decode</span><span class="p">(</span><span class="s">'utf-8'</span><span class="p">,</span> <span class="n">errors</span><span class="o">=</span><span class="s">'replace'</span><span class="p">)</span>
                    <span class="n">right_str</span> <span class="o">=</span> <span class="n">right_bytes</span><span class="p">.</span><span class="n">decode</span><span class="p">(</span><span class="s">'utf-8'</span><span class="p">,</span> <span class="n">errors</span><span class="o">=</span><span class="s">'replace'</span><span class="p">)</span>
                    <span class="n">merged_str</span> <span class="o">=</span> <span class="p">(</span><span class="n">left_bytes</span> <span class="o">+</span> <span class="n">right_bytes</span><span class="p">).</span><span class="n">decode</span><span class="p">(</span><span class="s">'utf-8'</span><span class="p">,</span> <span class="n">errors</span><span class="o">=</span><span class="s">'replace'</span><span class="p">)</span>
                    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Merge </span><span class="si">{</span><span class="n">merge_num</span> <span class="o">+</span> <span class="mi">1</span><span class="si">:</span><span class="mi">4</span><span class="n">d</span><span class="si">}</span><span class="s">/</span><span class="si">{</span><span class="n">target_merges</span><span class="si">}</span><span class="s">: "</span>
                          <span class="sa">f</span><span class="s">"'</span><span class="si">{</span><span class="n">left_str</span><span class="si">}</span><span class="s">' + '</span><span class="si">{</span><span class="n">right_str</span><span class="si">}</span><span class="s">' -&gt; '</span><span class="si">{</span><span class="n">merged_str</span><span class="si">}</span><span class="s">' "</span>
                          <span class="sa">f</span><span class="s">"(freq: </span><span class="si">{</span><span class="n">best_count</span><span class="si">:</span><span class="p">,</span><span class="si">}</span><span class="s">, time: </span><span class="si">{</span><span class="n">merge_step_time</span><span class="si">:</span><span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="s">s)"</span><span class="p">)</span>
                <span class="k">except</span><span class="p">:</span>
                    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Merge </span><span class="si">{</span><span class="n">merge_num</span> <span class="o">+</span> <span class="mi">1</span><span class="si">:</span><span class="mi">4</span><span class="n">d</span><span class="si">}</span><span class="s">/</span><span class="si">{</span><span class="n">target_merges</span><span class="si">}</span><span class="s">: "</span>
                          <span class="sa">f</span><span class="s">"</span><span class="si">{</span><span class="n">left_bytes</span><span class="si">}</span><span class="s"> + </span><span class="si">{</span><span class="n">right_bytes</span><span class="si">}</span><span class="s"> -&gt; </span><span class="si">{</span><span class="n">left_bytes</span> <span class="o">+</span> <span class="n">right_bytes</span><span class="si">}</span><span class="s"> "</span>
                          <span class="sa">f</span><span class="s">"(freq: </span><span class="si">{</span><span class="n">best_count</span><span class="si">:</span><span class="p">,</span><span class="si">}</span><span class="s">, time: </span><span class="si">{</span><span class="n">merge_step_time</span><span class="si">:</span><span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="s">s)"</span><span class="p">)</span>

    <span class="n">bpe_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">bpe_start_time</span>

    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="s">"="</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"BPE training completed in </span><span class="si">{</span><span class="n">bpe_time</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s"> seconds"</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Final vocabulary size: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">)</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Total merges performed: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">merges</span><span class="p">)</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

        <span class="c1"># Show compression statistics
</span>        <span class="k">if</span> <span class="n">word_counts</span><span class="p">:</span>
            <span class="n">original_tokens</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="nb">bytes</span><span class="p">(</span><span class="n">word_bytes</span><span class="p">))</span> <span class="k">for</span> <span class="n">word_bytes</span><span class="p">,</span> <span class="n">count</span> <span class="ow">in</span> <span class="n">word_counts</span><span class="p">.</span><span class="n">items</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">count</span><span class="p">))</span>
            <span class="n">compressed_tokens</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">word</span><span class="p">)</span> <span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">count</span> <span class="ow">in</span> <span class="n">word_freq</span><span class="p">.</span><span class="n">items</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">count</span><span class="p">))</span>
            <span class="n">compression_ratio</span> <span class="o">=</span> <span class="n">original_tokens</span> <span class="o">/</span> <span class="n">compressed_tokens</span> <span class="k">if</span> <span class="n">compressed_tokens</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mf">1.0</span>
            <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Compression ratio: </span><span class="si">{</span><span class="n">compression_ratio</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s">x (from </span><span class="si">{</span><span class="n">original_tokens</span><span class="si">:</span><span class="p">,</span><span class="si">}</span><span class="s"> to </span><span class="si">{</span><span class="n">compressed_tokens</span><span class="si">:</span><span class="p">,</span><span class="si">}</span><span class="s"> tokens)"</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">vocab</span><span class="p">,</span> <span class="n">merges</span>


<span class="k">def</span> <span class="nf">save_tokenizer</span><span class="p">(</span><span class="n">vocab</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">bytes</span><span class="p">],</span> <span class="n">merges</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">tuple</span><span class="p">[</span><span class="nb">bytes</span><span class="p">,</span> <span class="nb">bytes</span><span class="p">]],</span>
                  <span class="n">vocab_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">merges_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
    <span class="s">"""Save vocabulary and merges to disk files."""</span>
    <span class="kn">import</span> <span class="nn">json</span>
    <span class="kn">import</span> <span class="nn">pickle</span>

    <span class="c1"># Save vocabulary
</span>    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">vocab_path</span><span class="p">,</span> <span class="s">'wb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">pickle</span><span class="p">.</span><span class="n">dump</span><span class="p">(</span><span class="n">vocab</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>

    <span class="c1"># Save merges
</span>    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">merges_path</span><span class="p">,</span> <span class="s">'wb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">pickle</span><span class="p">.</span><span class="n">dump</span><span class="p">(</span><span class="n">merges</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">load_tokenizer</span><span class="p">(</span><span class="n">vocab_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">merges_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">bytes</span><span class="p">],</span> <span class="nb">list</span><span class="p">[</span><span class="nb">tuple</span><span class="p">[</span><span class="nb">bytes</span><span class="p">,</span> <span class="nb">bytes</span><span class="p">]]]:</span>
    <span class="s">"""Load vocabulary and merges from disk files."""</span>
    <span class="kn">import</span> <span class="nn">pickle</span>

    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">vocab_path</span><span class="p">,</span> <span class="s">'rb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">vocab</span> <span class="o">=</span> <span class="n">pickle</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>

    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">merges_path</span><span class="p">,</span> <span class="s">'rb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">merges</span> <span class="o">=</span> <span class="n">pickle</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">vocab</span><span class="p">,</span> <span class="n">merges</span>
</code></pre></div></div>

<h2 id="training-on-tinystories-dataset">Training on TinyStories Dataset</h2>

<p>Now let‚Äôs use our implementation to train a tokenizer on the TinyStories dataset. Here is one training function to demonstrate all the steps:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">os</span>

<span class="k">def</span> <span class="nf">train_bpe_tokentizer_via_dataset</span><span class="p">(</span><span class="n">input_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"="</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"BPE TOKENIZER TRAINING ON TINYSTORIES DATASET"</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"="</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>

    <span class="c1"># Configuration
</span>    <span class="n">vocab_size</span> <span class="o">=</span> <span class="mi">10000</span>
    <span class="n">special_tokens</span> <span class="o">=</span> <span class="p">[</span><span class="s">"&lt;|endoftext|&gt;"</span><span class="p">]</span>

    <span class="c1"># Check if input file exists
</span>    <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">exists</span><span class="p">(</span><span class="n">input_path</span><span class="p">):</span>
        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Error: Input file '</span><span class="si">{</span><span class="n">input_path</span><span class="si">}</span><span class="s">' not found!"</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s">"Please ensure the TinyStories dataset is in the data/ directory."</span><span class="p">)</span>
        <span class="k">return</span>

    <span class="c1"># Display configuration
</span>    <span class="n">file_size</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">getsize</span><span class="p">(</span><span class="n">input_path</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Configuration:"</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"  Input file: </span><span class="si">{</span><span class="n">input_path</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"  File size: </span><span class="si">{</span><span class="n">file_size</span><span class="si">:</span><span class="p">,</span><span class="si">}</span><span class="s"> bytes (</span><span class="si">{</span><span class="n">file_size</span> <span class="o">/</span> <span class="mi">1024</span> <span class="o">/</span> <span class="mi">1024</span><span class="si">:</span><span class="p">.</span><span class="mi">1</span><span class="n">f</span><span class="si">}</span><span class="s"> MB)"</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"  Target vocabulary size: </span><span class="si">{</span><span class="n">vocab_size</span><span class="si">:</span><span class="p">,</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"  Special tokens: </span><span class="si">{</span><span class="n">special_tokens</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"  Verbose logging: Enabled"</span><span class="p">)</span>
    <span class="k">print</span><span class="p">()</span>

    <span class="c1"># Train the tokenizer with verbose output
</span>    <span class="n">overall_start_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">vocab</span><span class="p">,</span> <span class="n">merges</span> <span class="o">=</span> <span class="n">train_bpe_tokenizer</span><span class="p">(</span>
        <span class="n">input_path</span><span class="o">=</span><span class="n">input_path</span><span class="p">,</span>
        <span class="n">vocab_size</span><span class="o">=</span><span class="n">vocab_size</span><span class="p">,</span>
        <span class="n">special_tokens</span><span class="o">=</span><span class="n">special_tokens</span><span class="p">,</span>
        <span class="n">verbose</span><span class="o">=</span><span class="bp">True</span>  <span class="c1"># Enable detailed logging
</span>    <span class="p">)</span>
    <span class="n">overall_end_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="n">time</span><span class="p">()</span>

    <span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s">"</span> <span class="o">+</span> <span class="s">"="</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"TRAINING SUMMARY"</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"="</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Total training time: </span><span class="si">{</span><span class="n">overall_end_time</span> <span class="o">-</span> <span class="n">overall_start_time</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s"> seconds"</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Final vocabulary size: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">)</span><span class="si">:</span><span class="p">,</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Number of merges performed: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">merges</span><span class="p">)</span><span class="si">:</span><span class="p">,</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Actual vocab size vs target: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">)</span><span class="si">}</span><span class="s"> / </span><span class="si">{</span><span class="n">vocab_size</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

    <span class="c1"># Save the tokenizer
</span>    <span class="n">vocab_path</span> <span class="o">=</span> <span class="s">"tinystories_vocab.pkl"</span>
    <span class="n">merges_path</span> <span class="o">=</span> <span class="s">"tinystories_merges.pkl"</span>

    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"</span><span class="se">\n</span><span class="s">Saving tokenizer to disk..."</span><span class="p">)</span>
    <span class="n">save_tokenizer</span><span class="p">(</span><span class="n">vocab</span><span class="p">,</span> <span class="n">merges</span><span class="p">,</span> <span class="n">vocab_path</span><span class="p">,</span> <span class="n">merges_path</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"  ‚úì Vocabulary saved to: </span><span class="si">{</span><span class="n">vocab_path</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"  ‚úì Merges saved to: </span><span class="si">{</span><span class="n">merges_path</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

    <span class="c1"># Detailed vocabulary analysis
</span>    <span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s">"</span> <span class="o">+</span> <span class="s">"="</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"VOCABULARY ANALYSIS"</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"="</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>

    <span class="c1"># Count different types of tokens
</span>    <span class="n">byte_tokens</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="mi">1</span> <span class="k">for</span> <span class="n">token_id</span> <span class="ow">in</span> <span class="n">vocab</span><span class="p">.</span><span class="n">keys</span><span class="p">()</span> <span class="k">if</span> <span class="n">token_id</span> <span class="o">&lt;</span> <span class="mi">256</span><span class="p">)</span>
    <span class="n">special_token_count</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">special_tokens</span><span class="p">)</span>
    <span class="n">merged_tokens</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">)</span> <span class="o">-</span> <span class="n">byte_tokens</span> <span class="o">-</span> <span class="n">special_token_count</span>

    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Token type breakdown:"</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"  Byte tokens (0-255): </span><span class="si">{</span><span class="n">byte_tokens</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"  Special tokens: </span><span class="si">{</span><span class="n">special_token_count</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"  Merged tokens: </span><span class="si">{</span><span class="n">merged_tokens</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"  Total: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">)</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

    <span class="c1"># Show some vocabulary examples
</span>    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"</span><span class="se">\n</span><span class="s">Byte tokens (first 10):"</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">vocab</span><span class="p">:</span>
            <span class="n">char</span> <span class="o">=</span> <span class="n">vocab</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">decode</span><span class="p">(</span><span class="s">'utf-8'</span><span class="p">,</span> <span class="n">errors</span><span class="o">=</span><span class="s">'replace'</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">char</span><span class="p">.</span><span class="n">isprintable</span><span class="p">()</span> <span class="ow">and</span> <span class="n">char</span> <span class="o">!=</span> <span class="s">' '</span><span class="p">:</span>
                <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"  Token </span><span class="si">{</span><span class="n">i</span><span class="si">:</span><span class="mi">3</span><span class="n">d</span><span class="si">}</span><span class="s">: </span><span class="si">{</span><span class="n">vocab</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="s"> -&gt; '</span><span class="si">{</span><span class="n">char</span><span class="si">}</span><span class="s">'"</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"  Token </span><span class="si">{</span><span class="n">i</span><span class="si">:</span><span class="mi">3</span><span class="n">d</span><span class="si">}</span><span class="s">: </span><span class="si">{</span><span class="n">vocab</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="s"> -&gt; </span><span class="si">{</span><span class="nb">repr</span><span class="p">(</span><span class="n">char</span><span class="p">)</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"</span><span class="se">\n</span><span class="s">Special tokens:"</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">token_str</span> <span class="ow">in</span> <span class="n">special_tokens</span><span class="p">:</span>
        <span class="n">token_bytes</span> <span class="o">=</span> <span class="n">token_str</span><span class="p">.</span><span class="n">encode</span><span class="p">(</span><span class="s">'utf-8'</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">token_id</span><span class="p">,</span> <span class="n">vocab_bytes</span> <span class="ow">in</span> <span class="n">vocab</span><span class="p">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">vocab_bytes</span> <span class="o">==</span> <span class="n">token_bytes</span><span class="p">:</span>
                <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"  Token </span><span class="si">{</span><span class="n">token_id</span><span class="si">:</span><span class="mi">3</span><span class="n">d</span><span class="si">}</span><span class="s">: </span><span class="si">{</span><span class="n">vocab_bytes</span><span class="si">}</span><span class="s"> -&gt; '</span><span class="si">{</span><span class="n">token_str</span><span class="si">}</span><span class="s">'"</span><span class="p">)</span>
                <span class="k">break</span>

    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"</span><span class="se">\n</span><span class="s">Most recently merged tokens (last 10):"</span><span class="p">)</span>
    <span class="n">merged_token_ids</span> <span class="o">=</span> <span class="p">[</span><span class="n">tid</span> <span class="k">for</span> <span class="n">tid</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">vocab</span><span class="p">.</span><span class="n">keys</span><span class="p">())</span> <span class="k">if</span> <span class="n">tid</span> <span class="o">&gt;=</span> <span class="mi">256</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">special_tokens</span><span class="p">)]</span>
    <span class="k">for</span> <span class="n">token_id</span> <span class="ow">in</span> <span class="n">merged_token_ids</span><span class="p">[</span><span class="o">-</span><span class="mi">10</span><span class="p">:]:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">decoded</span> <span class="o">=</span> <span class="n">vocab</span><span class="p">[</span><span class="n">token_id</span><span class="p">].</span><span class="n">decode</span><span class="p">(</span><span class="s">'utf-8'</span><span class="p">,</span> <span class="n">errors</span><span class="o">=</span><span class="s">'replace'</span><span class="p">)</span>
            <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"  Token </span><span class="si">{</span><span class="n">token_id</span><span class="si">:</span><span class="mi">4</span><span class="n">d</span><span class="si">}</span><span class="s">: </span><span class="si">{</span><span class="n">vocab</span><span class="p">[</span><span class="n">token_id</span><span class="p">]</span><span class="si">}</span><span class="s"> -&gt; '</span><span class="si">{</span><span class="n">decoded</span><span class="si">}</span><span class="s">'"</span><span class="p">)</span>
        <span class="k">except</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"  Token </span><span class="si">{</span><span class="n">token_id</span><span class="si">:</span><span class="mi">4</span><span class="n">d</span><span class="si">}</span><span class="s">: </span><span class="si">{</span><span class="n">vocab</span><span class="p">[</span><span class="n">token_id</span><span class="p">]</span><span class="si">}</span><span class="s"> -&gt; (non-UTF8)"</span><span class="p">)</span>

    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"</span><span class="se">\n</span><span class="s">First 10 merge operations:"</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">left</span><span class="p">,</span> <span class="n">right</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">merges</span><span class="p">[:</span><span class="mi">10</span><span class="p">]):</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">left_str</span> <span class="o">=</span> <span class="n">left</span><span class="p">.</span><span class="n">decode</span><span class="p">(</span><span class="s">'utf-8'</span><span class="p">,</span> <span class="n">errors</span><span class="o">=</span><span class="s">'replace'</span><span class="p">)</span>
            <span class="n">right_str</span> <span class="o">=</span> <span class="n">right</span><span class="p">.</span><span class="n">decode</span><span class="p">(</span><span class="s">'utf-8'</span><span class="p">,</span> <span class="n">errors</span><span class="o">=</span><span class="s">'replace'</span><span class="p">)</span>
            <span class="n">merged_str</span> <span class="o">=</span> <span class="p">(</span><span class="n">left</span> <span class="o">+</span> <span class="n">right</span><span class="p">).</span><span class="n">decode</span><span class="p">(</span><span class="s">'utf-8'</span><span class="p">,</span> <span class="n">errors</span><span class="o">=</span><span class="s">'replace'</span><span class="p">)</span>
            <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"  Merge </span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">:</span><span class="mi">2</span><span class="n">d</span><span class="si">}</span><span class="s">: '</span><span class="si">{</span><span class="n">left_str</span><span class="si">}</span><span class="s">' + '</span><span class="si">{</span><span class="n">right_str</span><span class="si">}</span><span class="s">' -&gt; '</span><span class="si">{</span><span class="n">merged_str</span><span class="si">}</span><span class="s">'"</span><span class="p">)</span>
        <span class="k">except</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"  Merge </span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">:</span><span class="mi">2</span><span class="n">d</span><span class="si">}</span><span class="s">: </span><span class="si">{</span><span class="n">left</span><span class="si">}</span><span class="s"> + </span><span class="si">{</span><span class="n">right</span><span class="si">}</span><span class="s"> -&gt; (binary)"</span><span class="p">)</span>

    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"</span><span class="se">\n</span><span class="s">Last 10 merge operations:"</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">left</span><span class="p">,</span> <span class="n">right</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">merges</span><span class="p">[</span><span class="o">-</span><span class="mi">10</span><span class="p">:],</span> <span class="nb">len</span><span class="p">(</span><span class="n">merges</span><span class="p">)</span> <span class="o">-</span> <span class="mi">9</span><span class="p">):</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">left_str</span> <span class="o">=</span> <span class="n">left</span><span class="p">.</span><span class="n">decode</span><span class="p">(</span><span class="s">'utf-8'</span><span class="p">,</span> <span class="n">errors</span><span class="o">=</span><span class="s">'replace'</span><span class="p">)</span>
            <span class="n">right_str</span> <span class="o">=</span> <span class="n">right</span><span class="p">.</span><span class="n">decode</span><span class="p">(</span><span class="s">'utf-8'</span><span class="p">,</span> <span class="n">errors</span><span class="o">=</span><span class="s">'replace'</span><span class="p">)</span>
            <span class="n">merged_str</span> <span class="o">=</span> <span class="p">(</span><span class="n">left</span> <span class="o">+</span> <span class="n">right</span><span class="p">).</span><span class="n">decode</span><span class="p">(</span><span class="s">'utf-8'</span><span class="p">,</span> <span class="n">errors</span><span class="o">=</span><span class="s">'replace'</span><span class="p">)</span>
            <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"  Merge </span><span class="si">{</span><span class="n">i</span><span class="si">:</span><span class="mi">2</span><span class="n">d</span><span class="si">}</span><span class="s">: '</span><span class="si">{</span><span class="n">left_str</span><span class="si">}</span><span class="s">' + '</span><span class="si">{</span><span class="n">right_str</span><span class="si">}</span><span class="s">' -&gt; '</span><span class="si">{</span><span class="n">merged_str</span><span class="si">}</span><span class="s">'"</span><span class="p">)</span>
        <span class="k">except</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"  Merge </span><span class="si">{</span><span class="n">i</span><span class="si">:</span><span class="mi">2</span><span class="n">d</span><span class="si">}</span><span class="s">: </span><span class="si">{</span><span class="n">left</span><span class="si">}</span><span class="s"> + </span><span class="si">{</span><span class="n">right</span><span class="si">}</span><span class="s"> -&gt; (binary)"</span><span class="p">)</span>

    <span class="c1"># Show file sizes
</span>    <span class="n">vocab_size_bytes</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">getsize</span><span class="p">(</span><span class="n">vocab_path</span><span class="p">)</span>
    <span class="n">merges_size_bytes</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">getsize</span><span class="p">(</span><span class="n">merges_path</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"</span><span class="se">\n</span><span class="s">Output file sizes:"</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"  Vocabulary file: </span><span class="si">{</span><span class="n">vocab_size_bytes</span><span class="si">:</span><span class="p">,</span><span class="si">}</span><span class="s"> bytes (</span><span class="si">{</span><span class="n">vocab_size_bytes</span> <span class="o">/</span> <span class="mi">1024</span><span class="si">:</span><span class="p">.</span><span class="mi">1</span><span class="n">f</span><span class="si">}</span><span class="s"> KB)"</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"  Merges file: </span><span class="si">{</span><span class="n">merges_size_bytes</span><span class="si">:</span><span class="p">,</span><span class="si">}</span><span class="s"> bytes (</span><span class="si">{</span><span class="n">merges_size_bytes</span> <span class="o">/</span> <span class="mi">1024</span><span class="si">:</span><span class="p">.</span><span class="mi">1</span><span class="n">f</span><span class="si">}</span><span class="s"> KB)"</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"  Total: </span><span class="si">{</span><span class="n">vocab_size_bytes</span> <span class="o">+</span> <span class="n">merges_size_bytes</span><span class="si">:</span><span class="p">,</span><span class="si">}</span><span class="s"> bytes (</span><span class="si">{</span><span class="p">(</span><span class="n">vocab_size_bytes</span> <span class="o">+</span> <span class="n">merges_size_bytes</span><span class="p">)</span> <span class="o">/</span> <span class="mi">1024</span><span class="si">:</span><span class="p">.</span><span class="mi">1</span><span class="n">f</span><span class="si">}</span><span class="s"> KB)"</span><span class="p">)</span>

    <span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s">"</span> <span class="o">+</span> <span class="s">"="</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"TRAINING COMPLETED SUCCESSFULLY!"</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"="</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"You can now use the trained tokenizer for encoding/decoding text."</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Load with: vocab, merges = load_tokenizer('</span><span class="si">{</span><span class="n">vocab_path</span><span class="si">}</span><span class="s">', '</span><span class="si">{</span><span class="n">merges_path</span><span class="si">}</span><span class="s">')"</span><span class="p">)</span>
</code></pre></div></div>

<p>To run the training, one can try for example:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train_bpe_tokentizer_via_dataset</span><span class="p">(</span><span class="n">input_path</span><span class="o">=</span><span class="s">"data/TinyStoriesV2-GPT4-train.txt"</span><span class="p">)</span>
</code></pre></div></div>

<p>And it will output the following info from the training process:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>================================================================================
BPE TOKENIZER TRAINING ON TINYSTORIES DATASET
================================================================================
Configuration:
  Input file: /content/TinyStoriesV2-GPT4-train.txt
  File size: 2,227,753,162 bytes (2124.6 MB)
  Target vocabulary size: 10,000
  Special tokens: ['&lt;|endoftext|&gt;']
  Verbose logging: Enabled

Step 1: Setting up parallel processing...
Using 12 processes for parallel tokenization
Finding chunk boundaries aligned with special token: &lt;|endoftext|&gt;
Initial guess of the chunk boundaries: [0, 185646096, 371292192, 556938288, 742584384, 928230480, 1113876576, 1299522672, 1485168768, 1670814864, 1856460960, 2042107056, 2227753152]
Created 12 chunks for processing

Step 2: Pre-tokenizing text corpus...
Pre-tokenization completed in 66.52 seconds
Found 59,904 unique word types
Total token count: 536,592,162
Most common words:
  1. '.' -&gt; 41,764,519 times
  2. ',' -&gt; 23,284,331 times
  3. ' the' -&gt; 20,828,576 times
  4. ' and' -&gt; 19,475,966 times
  5. ' a' -&gt; 15,063,529 times

Step 3: Training BPE with 9,743 merges...
Initial vocabulary size: 257 (256 bytes + 1 special tokens)
============================================================
Merge    1/9743: ' ' + 't' -&gt; ' t' (freq: 63,482,199, time: 0.273s)
Merge    2/9743: 'h' + 'e' -&gt; 'he' (freq: 63,341,860, time: 0.318s)
Merge    3/9743: ' ' + 'a' -&gt; ' a' (freq: 47,465,635, time: 0.340s)
Merge    4/9743: ' ' + 's' -&gt; ' s' (freq: 32,362,158, time: 0.340s)
Merge    5/9743: ' ' + 'w' -&gt; ' w' (freq: 31,485,643, time: 0.327s)
Merge    6/9743: 'n' + 'd' -&gt; 'nd' (freq: 28,922,386, time: 0.332s)
Merge    7/9743: ' t' + 'he' -&gt; ' the' (freq: 28,915,024, time: 0.320s)
Merge    8/9743: 'e' + 'd' -&gt; 'ed' (freq: 24,836,456, time: 0.317s)
Merge    9/9743: ' ' + 'b' -&gt; ' b' (freq: 22,147,488, time: 0.326s)
Merge   10/9743: ' t' + 'o' -&gt; ' to' (freq: 20,892,273, time: 0.322s)
Merge  100/9743: ' ha' + 'pp' -&gt; ' happ' (freq: 3,147,884, time: 0.251s)
Merge  200/9743: ' s' + 'e' -&gt; ' se' (freq: 1,410,130, time: 0.343s)
Merge  300/9743: ' s' + 'omet' -&gt; ' somet' (freq: 790,510, time: 0.245s)
Merge  400/9743: ' g' + 'ot' -&gt; ' got' (freq: 524,776, time: 0.338s)
Merge  500/9743: ' e' + 'ach' -&gt; ' each' (freq: 369,637, time: 0.321s)
Merge  600/9743: 'l' + 'f' -&gt; 'lf' (freq: 279,566, time: 0.230s)
Merge  700/9743: ' wal' + 'k' -&gt; ' walk' (freq: 221,114, time: 0.237s)
Merge  800/9743: ' do' + 'll' -&gt; ' doll' (freq: 177,602, time: 0.324s)
Merge  900/9743: ' ' + 'G' -&gt; ' G' (freq: 147,699, time: 0.214s)
Merge 1000/9743: 'ec' + 't' -&gt; 'ect' (freq: 127,288, time: 0.233s)
Merge 1100/9743: ' l' + 'ight' -&gt; ' light' (freq: 108,006, time: 0.208s)
Merge 1200/9743: ' d' + 'in' -&gt; ' din' (freq: 92,211, time: 0.225s)
Merge 1300/9743: ' picture' + 's' -&gt; ' pictures' (freq: 80,416, time: 0.318s)
Merge 1400/9743: 'itt' + 'en' -&gt; 'itten' (freq: 68,466, time: 0.235s)
Merge 1500/9743: 'A' + 'my' -&gt; 'Amy' (freq: 59,829, time: 0.306s)
Merge 1600/9743: ' tal' + 'king' -&gt; ' talking' (freq: 53,781, time: 0.330s)
Merge 1700/9743: 'b' + 'all' -&gt; 'ball' (freq: 48,005, time: 0.309s)
Merge 1800/9743: ' k' + 'iss' -&gt; ' kiss' (freq: 43,477, time: 0.318s)
...
Merge 8000/9743: ' mom' + 'mies' -&gt; ' mommies' (freq: 879, time: 0.205s)
Merge 8100/9743: ' cryst' + 'als' -&gt; ' crystals' (freq: 840, time: 0.299s)
Merge 8200/9743: ' playd' + 'ate' -&gt; ' playdate' (freq: 809, time: 0.283s)
Merge 8300/9743: ' support' + 'ing' -&gt; ' supporting' (freq: 778, time: 0.200s)
Merge 8400/9743: ' activ' + 'ity' -&gt; ' activity' (freq: 747, time: 0.300s)
Merge 8500/9743: 'L' + 'izzy' -&gt; 'Lizzy' (freq: 716, time: 0.284s)
Merge 8600/9743: 'er' + 'ing' -&gt; 'ering' (freq: 691, time: 0.311s)
Merge 8700/9743: ' tid' + 'ied' -&gt; ' tidied' (freq: 660, time: 0.308s)
Merge 8800/9743: 'f' + 'lowers' -&gt; 'flowers' (freq: 633, time: 0.295s)
Merge 8900/9743: ' Gra' + 'nd' -&gt; ' Grand' (freq: 609, time: 0.299s)
Merge 9000/9743: ' frustr' + 'ation' -&gt; ' frustration' (freq: 584, time: 0.301s)
Merge 9100/9743: 'amil' + 'iar' -&gt; 'amiliar' (freq: 561, time: 0.205s)
Merge 9200/9743: ' P' + 'retty' -&gt; ' Pretty' (freq: 542, time: 0.310s)
Merge 9300/9743: ' sal' + 'on' -&gt; ' salon' (freq: 521, time: 0.292s)
Merge 9400/9743: ' p' + 'ounced' -&gt; ' pounced' (freq: 502, time: 0.196s)
Merge 9500/9743: ' pops' + 'ic' -&gt; ' popsic' (freq: 485, time: 0.185s)
Merge 9600/9743: ' pain' + 'ful' -&gt; ' painful' (freq: 469, time: 0.298s)
Merge 9700/9743: 'solut' + 'ely' -&gt; 'solutely' (freq: 454, time: 0.308s)
============================================================
BPE training completed in 2731.72 seconds
Final vocabulary size: 10000
Total merges performed: 9743
Compression ratio: 4.07x (from 2,192,422,648 to 538,511,097 tokens)

================================================================================
TRAINING SUMMARY
================================================================================
Total training time: 2898.45 seconds
Final vocabulary size: 10,000
Number of merges performed: 9,743
Actual vocab size vs target: 10000 / 10000

Saving tokenizer to disk...
  ‚úì Vocabulary saved to: tinystories_vocab.pkl
  ‚úì Merges saved to: tinystories_merges.pkl

================================================================================
VOCABULARY ANALYSIS
================================================================================
Token type breakdown:
  Byte tokens (0-255): 256
  Special tokens: 1
  Merged tokens: 9743
  Total: 10000

Byte tokens (first 10):
  Token   0: b'\x00' -&gt; '\x00'
  Token   1: b'\x01' -&gt; '\x01'
  Token   2: b'\x02' -&gt; '\x02'
  Token   3: b'\x03' -&gt; '\x03'
  Token   4: b'\x04' -&gt; '\x04'
  Token   5: b'\x05' -&gt; '\x05'
  Token   6: b'\x06' -&gt; '\x06'
  Token   7: b'\x07' -&gt; '\x07'
  Token   8: b'\x08' -&gt; '\x08'
  Token   9: b'\t' -&gt; '\t'

Special tokens:
  Token 256: b'&lt;|endoftext|&gt;' -&gt; '&lt;|endoftext|&gt;'

Most recently merged tokens (last 10):
  Token 9990: b' improving' -&gt; ' improving'
  Token 9991: b' nicest' -&gt; ' nicest'
  Token 9992: b' whiskers' -&gt; ' whiskers'
  Token 9993: b' booth' -&gt; ' booth'
  Token 9994: b' Land' -&gt; ' Land'
  Token 9995: b'Rocky' -&gt; 'Rocky'
  Token 9996: b' meadows' -&gt; ' meadows'
  Token 9997: b' Starry' -&gt; ' Starry'
  Token 9998: b' imaginary' -&gt; ' imaginary'
  Token 9999: b' bold' -&gt; ' bold'

First 10 merge operations:
  Merge  1: ' ' + 't' -&gt; ' t'
  Merge  2: 'h' + 'e' -&gt; 'he'
  Merge  3: ' ' + 'a' -&gt; ' a'
  Merge  4: ' ' + 's' -&gt; ' s'
  Merge  5: ' ' + 'w' -&gt; ' w'
  Merge  6: 'n' + 'd' -&gt; 'nd'
  Merge  7: ' t' + 'he' -&gt; ' the'
  Merge  8: 'e' + 'd' -&gt; 'ed'
  Merge  9: ' ' + 'b' -&gt; ' b'
  Merge 10: ' t' + 'o' -&gt; ' to'

Last 10 merge operations:
  Merge 9734: ' impro' + 'ving' -&gt; ' improving'
  Merge 9735: ' nice' + 'st' -&gt; ' nicest'
  Merge 9736: ' wh' + 'iskers' -&gt; ' whiskers'
  Merge 9737: ' bo' + 'oth' -&gt; ' booth'
  Merge 9738: ' L' + 'and' -&gt; ' Land'
  Merge 9739: 'Rock' + 'y' -&gt; 'Rocky'
  Merge 9740: ' meadow' + 's' -&gt; ' meadows'
  Merge 9741: ' St' + 'arry' -&gt; ' Starry'
  Merge 9742: ' imag' + 'inary' -&gt; ' imaginary'
  Merge 9743: ' bo' + 'ld' -&gt; ' bold'

Output file sizes:
  Vocabulary file: 117,701 bytes (114.9 KB)
  Merges file: 109,714 bytes (107.1 KB)
  Total: 227,415 bytes (222.1 KB)

================================================================================
TRAINING COMPLETED SUCCESSFULLY!
================================================================================
You can now use the trained tokenizer for encoding/decoding text.
Load with: vocab, merges = load_tokenizer('tinystories_vocab.pkl', 'tinystories_merges.pkl')
</code></pre></div></div>

<h2 id="using-the-trained-tokenizer">Using the Trained Tokenizer</h2>

<p>Once we have a trained tokenizer, we need a class to encode and decode text. Here‚Äôs one complete implementation:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">SimpleBPETokenizer</span><span class="p">:</span>
    <span class="s">"""Simple BPE tokenizer for encoding/decoding text."""</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab</span><span class="p">,</span> <span class="n">merges</span><span class="p">,</span> <span class="n">special_tokens</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">vocab</span> <span class="o">=</span> <span class="n">vocab</span>  <span class="c1"># {token_id: bytes}
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">merges</span> <span class="o">=</span> <span class="n">merges</span>  <span class="c1"># [(left_bytes, right_bytes), ...]
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">special_tokens</span> <span class="o">=</span> <span class="n">special_tokens</span> <span class="ow">or</span> <span class="p">[</span><span class="s">"&lt;|endoftext|&gt;"</span><span class="p">]</span>

        <span class="c1"># Create reverse mapping for decoding
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">id_to_bytes</span> <span class="o">=</span> <span class="n">vocab</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">bytes_to_id</span> <span class="o">=</span> <span class="p">{</span><span class="n">v</span><span class="p">:</span> <span class="n">k</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">vocab</span><span class="p">.</span><span class="n">items</span><span class="p">()}</span>

        <span class="c1"># GPT-2 style regex pattern
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">pattern</span> <span class="o">=</span> <span class="sa">r</span><span class="s">"""'(?:[sdmt]|ll|ve|re)| ?[a-zA-Z√Ä-√ø]+| ?[0-9]+| ?[^\s\w]+|\s+(?!\S)|\s+"""</span>

        <span class="c1"># Build merge rules for faster encoding
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">merge_rules</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">left_bytes</span><span class="p">,</span> <span class="n">right_bytes</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">merges</span><span class="p">):</span>
            <span class="c1"># Find what tokens these bytes correspond to
</span>            <span class="n">left_id</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">bytes_to_id</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="n">left_bytes</span><span class="p">)</span>
            <span class="n">right_id</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">bytes_to_id</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="n">right_bytes</span><span class="p">)</span>
            <span class="n">merged_bytes</span> <span class="o">=</span> <span class="n">left_bytes</span> <span class="o">+</span> <span class="n">right_bytes</span>
            <span class="n">merged_id</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">bytes_to_id</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="n">merged_bytes</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">left_id</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span> <span class="ow">and</span> <span class="n">right_id</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span> <span class="ow">and</span> <span class="n">merged_id</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="p">.</span><span class="n">merge_rules</span><span class="p">[(</span><span class="n">left_id</span><span class="p">,</span> <span class="n">right_id</span><span class="p">)]</span> <span class="o">=</span> <span class="n">merged_id</span>

    <span class="k">def</span> <span class="nf">encode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">]:</span>
        <span class="s">"""Encode text to token IDs."""</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">text</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">[]</span>

        <span class="c1"># Handle special tokens
</span>        <span class="n">token_ids</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">remaining_text</span> <span class="o">=</span> <span class="n">text</span>

        <span class="c1"># Split on special tokens first
</span>        <span class="k">for</span> <span class="n">special_token</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">.</span><span class="n">special_tokens</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">special_token</span> <span class="ow">in</span> <span class="n">remaining_text</span><span class="p">:</span>
                <span class="n">parts</span> <span class="o">=</span> <span class="n">remaining_text</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="n">special_token</span><span class="p">)</span>
                <span class="n">new_parts</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">part</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">parts</span><span class="p">):</span>
                    <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                        <span class="c1"># Add special token
</span>                        <span class="n">special_bytes</span> <span class="o">=</span> <span class="n">special_token</span><span class="p">.</span><span class="n">encode</span><span class="p">(</span><span class="s">'utf-8'</span><span class="p">)</span>
                        <span class="n">special_id</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">bytes_to_id</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="n">special_bytes</span><span class="p">)</span>
                        <span class="k">if</span> <span class="n">special_id</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
                            <span class="n">token_ids</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">special_id</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">part</span><span class="p">:</span>
                        <span class="n">new_parts</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">part</span><span class="p">)</span>
                <span class="n">remaining_text</span> <span class="o">=</span> <span class="s">''</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">new_parts</span><span class="p">)</span>

        <span class="c1"># Apply regex tokenization
</span>        <span class="k">for</span> <span class="n">match</span> <span class="ow">in</span> <span class="n">re</span><span class="p">.</span><span class="n">finditer</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">pattern</span><span class="p">,</span> <span class="n">remaining_text</span><span class="p">):</span>
            <span class="n">word</span> <span class="o">=</span> <span class="n">match</span><span class="p">.</span><span class="n">group</span><span class="p">()</span>
            <span class="n">word_tokens</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">_encode_word</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
            <span class="n">token_ids</span><span class="p">.</span><span class="n">extend</span><span class="p">(</span><span class="n">word_tokens</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">token_ids</span>

    <span class="k">def</span> <span class="nf">_encode_word</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">word</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">]:</span>
        <span class="s">"""Encode a single word using BPE merges."""</span>
        <span class="c1"># Start with individual bytes
</span>        <span class="n">word_bytes</span> <span class="o">=</span> <span class="n">word</span><span class="p">.</span><span class="n">encode</span><span class="p">(</span><span class="s">'utf-8'</span><span class="p">)</span>
        <span class="n">tokens</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># Convert each byte to its token ID
</span>        <span class="k">for</span> <span class="n">byte_val</span> <span class="ow">in</span> <span class="n">word_bytes</span><span class="p">:</span>
            <span class="n">tokens</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">byte_val</span><span class="p">)</span>  <span class="c1"># Byte token IDs are 0-255
</span>
        <span class="c1"># Apply BPE merges
</span>        <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="c1"># Find the best merge to apply
</span>            <span class="n">best_merge</span> <span class="o">=</span> <span class="bp">None</span>
            <span class="n">best_pos</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
            <span class="n">best_merge_priority</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s">'inf'</span><span class="p">)</span>

            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
                <span class="n">pair</span> <span class="o">=</span> <span class="p">(</span><span class="n">tokens</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">tokens</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">])</span>
                <span class="k">if</span> <span class="n">pair</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">.</span><span class="n">merge_rules</span><span class="p">:</span>
                    <span class="c1"># Find merge priority (earlier merges have higher priority)
</span>                    <span class="n">merged_bytes</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">id_to_bytes</span><span class="p">[</span><span class="n">tokens</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="o">+</span> <span class="bp">self</span><span class="p">.</span><span class="n">id_to_bytes</span><span class="p">[</span><span class="n">tokens</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]]</span>
                    <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="p">(</span><span class="n">left_bytes</span><span class="p">,</span> <span class="n">right_bytes</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">merges</span><span class="p">):</span>
                        <span class="k">if</span> <span class="n">left_bytes</span> <span class="o">+</span> <span class="n">right_bytes</span> <span class="o">==</span> <span class="n">merged_bytes</span><span class="p">:</span>
                            <span class="k">if</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="n">best_merge_priority</span><span class="p">:</span>
                                <span class="n">best_merge</span> <span class="o">=</span> <span class="n">pair</span>
                                <span class="n">best_pos</span> <span class="o">=</span> <span class="n">i</span>
                                <span class="n">best_merge_priority</span> <span class="o">=</span> <span class="n">j</span>
                            <span class="k">break</span>

            <span class="k">if</span> <span class="n">best_merge</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
                <span class="k">break</span>

            <span class="c1"># Apply the best merge
</span>            <span class="n">new_tokens</span> <span class="o">=</span> <span class="n">tokens</span><span class="p">[:</span><span class="n">best_pos</span><span class="p">]</span>
            <span class="n">new_tokens</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">merge_rules</span><span class="p">[</span><span class="n">best_merge</span><span class="p">])</span>
            <span class="n">new_tokens</span><span class="p">.</span><span class="n">extend</span><span class="p">(</span><span class="n">tokens</span><span class="p">[</span><span class="n">best_pos</span> <span class="o">+</span> <span class="mi">2</span><span class="p">:])</span>
            <span class="n">tokens</span> <span class="o">=</span> <span class="n">new_tokens</span>

        <span class="k">return</span> <span class="n">tokens</span>

    <span class="k">def</span> <span class="nf">decode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token_ids</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="s">"""Decode token IDs back to text."""</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">token_ids</span><span class="p">:</span>
            <span class="k">return</span> <span class="s">""</span>

        <span class="c1"># Convert token IDs to bytes
</span>        <span class="n">byte_sequences</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">token_id</span> <span class="ow">in</span> <span class="n">token_ids</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">token_id</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">.</span><span class="n">id_to_bytes</span><span class="p">:</span>
                <span class="n">byte_sequences</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">id_to_bytes</span><span class="p">[</span><span class="n">token_id</span><span class="p">])</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Handle unknown tokens
</span>                <span class="n">byte_sequences</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="sa">b</span><span class="s">'&lt;UNK&gt;'</span><span class="p">)</span>

        <span class="c1"># Concatenate all bytes and decode
</span>        <span class="n">all_bytes</span> <span class="o">=</span> <span class="sa">b</span><span class="s">''</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">byte_sequences</span><span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">all_bytes</span><span class="p">.</span><span class="n">decode</span><span class="p">(</span><span class="s">'utf-8'</span><span class="p">,</span> <span class="n">errors</span><span class="o">=</span><span class="s">'replace'</span><span class="p">)</span>
        <span class="k">except</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">all_bytes</span><span class="p">.</span><span class="n">decode</span><span class="p">(</span><span class="s">'utf-8'</span><span class="p">,</span> <span class="n">errors</span><span class="o">=</span><span class="s">'ignore'</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">tokenize_with_details</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
        <span class="s">"""Tokenize text and show detailed breakdown."""</span>
        <span class="n">token_ids</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">encode</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>

        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Original text: '</span><span class="si">{</span><span class="n">text</span><span class="si">}</span><span class="s">'"</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Length: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">text</span><span class="p">)</span><span class="si">}</span><span class="s"> characters"</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"UTF-8 bytes: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">text</span><span class="p">.</span><span class="n">encode</span><span class="p">(</span><span class="s">'utf-8'</span><span class="p">))</span><span class="si">}</span><span class="s"> bytes"</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Token count: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">token_ids</span><span class="p">)</span><span class="si">}</span><span class="s"> tokens"</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Compression ratio: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">text</span><span class="p">.</span><span class="n">encode</span><span class="p">(</span><span class="s">'utf-8'</span><span class="p">))</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">token_ids</span><span class="p">)</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s">x"</span><span class="p">)</span>
        <span class="k">print</span><span class="p">()</span>

        <span class="k">print</span><span class="p">(</span><span class="s">"Token breakdown:"</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">token_id</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">token_ids</span><span class="p">):</span>
            <span class="n">token_bytes</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">id_to_bytes</span><span class="p">[</span><span class="n">token_id</span><span class="p">]</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">token_str</span> <span class="o">=</span> <span class="n">token_bytes</span><span class="p">.</span><span class="n">decode</span><span class="p">(</span><span class="s">'utf-8'</span><span class="p">,</span> <span class="n">errors</span><span class="o">=</span><span class="s">'replace'</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">token_str</span><span class="p">.</span><span class="n">isprintable</span><span class="p">():</span>
                    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"  </span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">:</span><span class="mi">2</span><span class="n">d</span><span class="si">}</span><span class="s">. Token </span><span class="si">{</span><span class="n">token_id</span><span class="si">:</span><span class="mi">4</span><span class="n">d</span><span class="si">}</span><span class="s">: '</span><span class="si">{</span><span class="n">token_str</span><span class="si">}</span><span class="s">' (</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">token_bytes</span><span class="p">)</span><span class="si">}</span><span class="s"> bytes)"</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"  </span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">:</span><span class="mi">2</span><span class="n">d</span><span class="si">}</span><span class="s">. Token </span><span class="si">{</span><span class="n">token_id</span><span class="si">:</span><span class="mi">4</span><span class="n">d</span><span class="si">}</span><span class="s">: </span><span class="si">{</span><span class="nb">repr</span><span class="p">(</span><span class="n">token_str</span><span class="p">)</span><span class="si">}</span><span class="s"> (</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">token_bytes</span><span class="p">)</span><span class="si">}</span><span class="s"> bytes)"</span><span class="p">)</span>
            <span class="k">except</span><span class="p">:</span>
                <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"  </span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">:</span><span class="mi">2</span><span class="n">d</span><span class="si">}</span><span class="s">. Token </span><span class="si">{</span><span class="n">token_id</span><span class="si">:</span><span class="mi">4</span><span class="n">d</span><span class="si">}</span><span class="s">: </span><span class="si">{</span><span class="n">token_bytes</span><span class="si">}</span><span class="s"> (binary)"</span><span class="p">)</span>

        <span class="c1"># Verify round-trip
</span>        <span class="n">decoded</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">decode</span><span class="p">(</span><span class="n">token_ids</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"</span><span class="se">\n</span><span class="s">Decoded text: '</span><span class="si">{</span><span class="n">decoded</span><span class="si">}</span><span class="s">'"</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Round-trip successful: </span><span class="si">{</span><span class="n">text</span> <span class="o">==</span> <span class="n">decoded</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">token_ids</span>
</code></pre></div></div>

<p>Let us compose some simple test cases below:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">test_bpe_tokenizer</span><span class="p">():</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"="</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"BPE TOKENIZER SAMPLE TESTS"</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"="</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>

    <span class="c1"># Load the trained tokenizer
</span>    <span class="k">try</span><span class="p">:</span>
        <span class="n">vocab</span><span class="p">,</span> <span class="n">merges</span> <span class="o">=</span> <span class="n">load_tokenizer</span><span class="p">(</span><span class="s">'tinystories_vocab.pkl'</span><span class="p">,</span> <span class="s">'tinystories_merges.pkl'</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"‚úì Loaded tokenizer with </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">)</span><span class="si">}</span><span class="s"> vocab entries and </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">merges</span><span class="p">)</span><span class="si">}</span><span class="s"> merges"</span><span class="p">)</span>
    <span class="k">except</span> <span class="nb">FileNotFoundError</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="s">"Error: Tokenizer files not found!"</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s">"Please run the training script first to create 'tinystories_vocab.pkl' and 'tinystories_merges.pkl'"</span><span class="p">)</span>
        <span class="k">return</span>

    <span class="c1"># Create tokenizer instance
</span>    <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">SimpleBPETokenizer</span><span class="p">(</span><span class="n">vocab</span><span class="p">,</span> <span class="n">merges</span><span class="p">)</span>
    <span class="k">print</span><span class="p">()</span>

    <span class="c1"># Example 1: Simple sentence
</span>    <span class="k">print</span><span class="p">(</span><span class="s">"EXAMPLE 1: Simple sentence"</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"-"</span> <span class="o">*</span> <span class="mi">30</span><span class="p">)</span>
    <span class="n">text1</span> <span class="o">=</span> <span class="s">"Hello world! How are you today?"</span>
    <span class="n">tokenizer</span><span class="p">.</span><span class="n">tokenize_with_details</span><span class="p">(</span><span class="n">text1</span><span class="p">)</span>
    <span class="k">print</span><span class="p">()</span>

    <span class="c1"># Example 2: Text with special token
</span>    <span class="k">print</span><span class="p">(</span><span class="s">"EXAMPLE 2: Text with special token"</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"-"</span> <span class="o">*</span> <span class="mi">30</span><span class="p">)</span>
    <span class="n">text2</span> <span class="o">=</span> <span class="s">"Once upon a time&lt;|endoftext|&gt;The end."</span>
    <span class="n">tokenizer</span><span class="p">.</span><span class="n">tokenize_with_details</span><span class="p">(</span><span class="n">text2</span><span class="p">)</span>
    <span class="k">print</span><span class="p">()</span>

    <span class="c1"># Example 3: Repeated words (should compress well)
</span>    <span class="k">print</span><span class="p">(</span><span class="s">"EXAMPLE 3: Repeated words"</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"-"</span> <span class="o">*</span> <span class="mi">30</span><span class="p">)</span>
    <span class="n">text3</span> <span class="o">=</span> <span class="s">"the the the cat cat sat sat on on the the mat mat"</span>
    <span class="n">tokenizer</span><span class="p">.</span><span class="n">tokenize_with_details</span><span class="p">(</span><span class="n">text3</span><span class="p">)</span>
    <span class="k">print</span><span class="p">()</span>

    <span class="c1"># Example 4: Numbers and punctuation
</span>    <span class="k">print</span><span class="p">(</span><span class="s">"EXAMPLE 4: Numbers and punctuation"</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"-"</span> <span class="o">*</span> <span class="mi">30</span><span class="p">)</span>
    <span class="n">text4</span> <span class="o">=</span> <span class="s">"I have 123 apples, 456 oranges, and 789 bananas!"</span>
    <span class="n">tokenizer</span><span class="p">.</span><span class="n">tokenize_with_details</span><span class="p">(</span><span class="n">text4</span><span class="p">)</span>
    <span class="k">print</span><span class="p">()</span>

    <span class="c1"># Example 5: Just encoding/decoding
</span>    <span class="k">print</span><span class="p">(</span><span class="s">"EXAMPLE 5: Simple encode/decode"</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"-"</span> <span class="o">*</span> <span class="mi">30</span><span class="p">)</span>
    <span class="n">text5</span> <span class="o">=</span> <span class="s">"This is a test."</span>
    <span class="n">token_ids</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">encode</span><span class="p">(</span><span class="n">text5</span><span class="p">)</span>
    <span class="n">decoded_text</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">decode</span><span class="p">(</span><span class="n">token_ids</span><span class="p">)</span>

    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Original: '</span><span class="si">{</span><span class="n">text5</span><span class="si">}</span><span class="s">'"</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Token IDs: </span><span class="si">{</span><span class="n">token_ids</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Decoded: '</span><span class="si">{</span><span class="n">decoded_text</span><span class="si">}</span><span class="s">'"</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Match: </span><span class="si">{</span><span class="n">text5</span> <span class="o">==</span> <span class="n">decoded_text</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
    <span class="k">print</span><span class="p">()</span>

    <span class="c1"># Show some vocabulary statistics
</span>    <span class="k">print</span><span class="p">(</span><span class="s">"VOCABULARY STATISTICS"</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"-"</span> <span class="o">*</span> <span class="mi">30</span><span class="p">)</span>
    <span class="n">byte_tokens</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="mi">1</span> <span class="k">for</span> <span class="n">tid</span> <span class="ow">in</span> <span class="n">vocab</span><span class="p">.</span><span class="n">keys</span><span class="p">()</span> <span class="k">if</span> <span class="n">tid</span> <span class="o">&lt;</span> <span class="mi">256</span><span class="p">)</span>
    <span class="n">special_tokens</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="mi">1</span> <span class="k">for</span> <span class="n">tid</span><span class="p">,</span> <span class="n">token_bytes</span> <span class="ow">in</span> <span class="n">vocab</span><span class="p">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="sa">b</span><span class="s">'&lt;|'</span> <span class="ow">in</span> <span class="n">token_bytes</span><span class="p">)</span>
    <span class="n">merged_tokens</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">)</span> <span class="o">-</span> <span class="n">byte_tokens</span> <span class="o">-</span> <span class="n">special_tokens</span>

    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Byte tokens (0-255): </span><span class="si">{</span><span class="n">byte_tokens</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Special tokens: </span><span class="si">{</span><span class="n">special_tokens</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Merged tokens: </span><span class="si">{</span><span class="n">merged_tokens</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Total vocabulary: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">)</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

    <span class="c1"># Show some example merged tokens
</span>    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"</span><span class="se">\n</span><span class="s">Sample merged tokens:"</span><span class="p">)</span>
    <span class="n">merged_token_ids</span> <span class="o">=</span> <span class="p">[</span><span class="n">tid</span> <span class="k">for</span> <span class="n">tid</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">vocab</span><span class="p">.</span><span class="n">keys</span><span class="p">())</span> <span class="k">if</span> <span class="n">tid</span> <span class="o">&gt;=</span> <span class="mi">257</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">token_id</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">merged_token_ids</span><span class="p">[:</span><span class="mi">10</span><span class="p">]):</span>
        <span class="n">token_bytes</span> <span class="o">=</span> <span class="n">vocab</span><span class="p">[</span><span class="n">token_id</span><span class="p">]</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">decoded</span> <span class="o">=</span> <span class="n">token_bytes</span><span class="p">.</span><span class="n">decode</span><span class="p">(</span><span class="s">'utf-8'</span><span class="p">,</span> <span class="n">errors</span><span class="o">=</span><span class="s">'replace'</span><span class="p">)</span>
            <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"  Token </span><span class="si">{</span><span class="n">token_id</span><span class="si">}</span><span class="s">: '</span><span class="si">{</span><span class="n">decoded</span><span class="si">}</span><span class="s">' (</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">token_bytes</span><span class="p">)</span><span class="si">}</span><span class="s"> bytes)"</span><span class="p">)</span>
        <span class="k">except</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"  Token </span><span class="si">{</span><span class="n">token_id</span><span class="si">}</span><span class="s">: </span><span class="si">{</span><span class="n">token_bytes</span><span class="si">}</span><span class="s"> (binary)"</span><span class="p">)</span>

    <span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s">"</span> <span class="o">+</span> <span class="s">"="</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"All examples completed successfully!"</span><span class="p">)</span>
</code></pre></div></div>

<h1 id="bpe-tokenizer-sample-tests">BPE Tokenizer Sample Tests</h1>

<p>Now run our complete test suite:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">test_bpe_tokenizer</span><span class="p">()</span>
</code></pre></div></div>
<p>Based on the training output from the TinyStories dataset, here are the testing results:</p>

<p>‚úì Loaded tokenizer with 10000 vocab entries and 9743 merges</p>

<h2 id="example-1-simple-sentence">Example 1: Simple sentence</h2>

<p><strong>Original text:</strong> ‚ÄòHello world! How are you today?‚Äô<br />
<strong>Length:</strong> 31 characters<br />
<strong>UTF-8 bytes:</strong> 31 bytes<br />
<strong>Token count:</strong> 8 tokens<br />
<strong>Compression ratio:</strong> 3.88x</p>

<h3 id="token-breakdown">Token breakdown:</h3>
<ol>
  <li>Token 1183: ‚ÄòHello‚Äô (5 bytes)</li>
  <li>Token 1569: ‚Äò world‚Äô (6 bytes)</li>
  <li>Token 33: ‚Äò!‚Äô (1 bytes)</li>
  <li>Token 2683: ‚Äò How‚Äô (4 bytes)</li>
  <li>Token 483: ‚Äò are‚Äô (4 bytes)</li>
  <li>Token 349: ‚Äò you‚Äô (4 bytes)</li>
  <li>Token 1709: ‚Äò today‚Äô (6 bytes)</li>
  <li>Token 63: ‚Äò?‚Äô (1 bytes)</li>
</ol>

<p><strong>Decoded text:</strong> ‚ÄòHello world! How are you today?‚Äô<br />
<strong>Round-trip successful:</strong> True</p>

<h2 id="example-2-text-with-special-token">Example 2: Text with special token</h2>

<p><strong>Original text:</strong> ‚ÄòOnce upon a time&lt;|endoftext|&gt;The end.‚Äô<br />
<strong>Length:</strong> 37 characters<br />
<strong>UTF-8 bytes:</strong> 37 bytes<br />
<strong>Token count:</strong> 8 tokens<br />
<strong>Compression ratio:</strong> 4.62x</p>

<h3 id="token-breakdown-1">Token breakdown:</h3>
<ol>
  <li>Token 256: ‚Äò<code class="language-plaintext highlighter-rouge">&lt;|endoftext|&gt;</code>‚Äô (13 bytes)</li>
  <li>Token 430: ‚ÄòOnce‚Äô (4 bytes)</li>
  <li>Token 439: ‚Äò upon‚Äô (5 bytes)</li>
  <li>Token 259: ‚Äò a‚Äô (2 bytes)</li>
  <li>Token 398: ‚Äò time‚Äô (5 bytes)</li>
  <li>Token 410: ‚ÄòThe‚Äô (3 bytes)</li>
  <li>Token 870: ‚Äò end‚Äô (4 bytes)</li>
  <li>Token 46: ‚Äò.‚Äô (1 bytes)</li>
</ol>

<p><strong>Decoded text:</strong> ‚Äò&lt;|endoftext|&gt;Once upon a timeThe end.‚Äô<br />
<strong>Round-trip successful:</strong> False</p>

<h2 id="example-3-repeated-words">Example 3: Repeated words</h2>

<p><strong>Original text:</strong> ‚Äòthe the the cat cat sat sat on on the the mat mat‚Äô<br />
<strong>Length:</strong> 49 characters<br />
<strong>UTF-8 bytes:</strong> 49 bytes<br />
<strong>Token count:</strong> 13 tokens<br />
<strong>Compression ratio:</strong> 3.77x</p>

<h3 id="token-breakdown-2">Token breakdown:</h3>
<ol>
  <li>Token 7199: ‚Äòthe‚Äô (3 bytes)</li>
  <li>Token 263: ‚Äò the‚Äô (4 bytes)</li>
  <li>Token 263: ‚Äò the‚Äô (4 bytes)</li>
  <li>Token 459: ‚Äò cat‚Äô (4 bytes)</li>
  <li>Token 459: ‚Äò cat‚Äô (4 bytes)</li>
  <li>Token 1091: ‚Äò sat‚Äô (4 bytes)</li>
  <li>Token 1091: ‚Äò sat‚Äô (4 bytes)</li>
  <li>Token 354: ‚Äò on‚Äô (3 bytes)</li>
  <li>Token 354: ‚Äò on‚Äô (3 bytes)</li>
  <li>Token 263: ‚Äò the‚Äô (4 bytes)</li>
  <li>Token 263: ‚Äò the‚Äô (4 bytes)</li>
  <li>Token 1492: ‚Äò mat‚Äô (4 bytes)</li>
  <li>Token 1492: ‚Äò mat‚Äô (4 bytes)</li>
</ol>

<p><strong>Decoded text:</strong> ‚Äòthe the the cat cat sat sat on on the the mat mat‚Äô<br />
<strong>Round-trip successful:</strong> True</p>

<h2 id="example-4-numbers-and-punctuation">Example 4: Numbers and punctuation</h2>

<p><strong>Original text:</strong> ‚ÄòI have 123 apples, 456 oranges, and 789 bananas!‚Äô<br />
<strong>Length:</strong> 48 characters<br />
<strong>UTF-8 bytes:</strong> 48 bytes<br />
<strong>Token count:</strong> 19 tokens<br />
<strong>Compression ratio:</strong> 2.53x</p>

<h3 id="token-breakdown-3">Token breakdown:</h3>
<ol>
  <li>Token 73: ‚ÄòI‚Äô (1 bytes)</li>
  <li>Token 499: ‚Äò have‚Äô (5 bytes)</li>
  <li>Token 6314: ‚Äò 1‚Äô (2 bytes)</li>
  <li>Token 50: ‚Äò2‚Äô (1 bytes)</li>
  <li>Token 51: ‚Äò3‚Äô (1 bytes)</li>
  <li>Token 1836: ‚Äò apples‚Äô (7 bytes)</li>
  <li>Token 44: ‚Äò,‚Äô (1 bytes)</li>
  <li>Token 9079: ‚Äò 4‚Äô (2 bytes)</li>
  <li>Token 53: ‚Äò5‚Äô (1 bytes)</li>
  <li>Token 54: ‚Äò6‚Äô (1 bytes)</li>
  <li>Token 5193: ‚Äò oranges‚Äô (8 bytes)</li>
  <li>Token 44: ‚Äò,‚Äô (1 bytes)</li>
  <li>Token 267: ‚Äò and‚Äô (4 bytes)</li>
  <li>Token 32: ‚Äò ‚Äò (1 bytes)</li>
  <li>Token 55: ‚Äò7‚Äô (1 bytes)</li>
  <li>Token 56: ‚Äò8‚Äô (1 bytes)</li>
  <li>Token 57: ‚Äò9‚Äô (1 bytes)</li>
  <li>Token 3898: ‚Äò bananas‚Äô (8 bytes)</li>
  <li>Token 33: ‚Äò!‚Äô (1 bytes)</li>
</ol>

<p><strong>Decoded text:</strong> ‚ÄòI have 123 apples, 456 oranges, and 789 bananas!‚Äô<br />
<strong>Round-trip successful:</strong> True</p>

<h2 id="example-5-simple-encodedecode">Example 5: Simple encode/decode</h2>

<p><strong>Original:</strong> ‚ÄòThis is a test.‚Äô<br />
<strong>Token IDs:</strong> [1531, 431, 259, 2569, 46]<br />
<strong>Decoded:</strong> ‚ÄòThis is a test.‚Äô<br />
<strong>Match:</strong> True</p>

<h2 id="vocabulary-statistics">Vocabulary Statistics</h2>

<p><strong>Byte tokens (0-255):</strong> 256<br />
<strong>Special tokens:</strong> 1<br />
<strong>Merged tokens:</strong> 9743<br />
<strong>Total vocabulary:</strong> 10000</p>

<h3 id="sample-merged-tokens">Sample merged tokens:</h3>
<ul>
  <li>Token 257: ‚Äò t‚Äô (2 bytes)</li>
  <li>Token 258: ‚Äòhe‚Äô (2 bytes)</li>
  <li>Token 259: ‚Äò a‚Äô (2 bytes)</li>
  <li>Token 260: ‚Äò s‚Äô (2 bytes)</li>
  <li>Token 261: ‚Äò w‚Äô (2 bytes)</li>
  <li>Token 262: ‚Äònd‚Äô (2 bytes)</li>
  <li>Token 263: ‚Äò the‚Äô (4 bytes)</li>
  <li>Token 264: ‚Äòed‚Äô (2 bytes)</li>
  <li>Token 265: ‚Äò b‚Äô (2 bytes)</li>
  <li>Token 266: ‚Äò to‚Äô (3 bytes)</li>
</ul>

<hr />
<p>All examples completed successfully!</p>


  </div><a class="u-url" href="/cs336/2025/07/26/cs336-note-train-bpe-tinystories.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="http://localhost:4000/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>I chronicle my captivating journey through Generative AI, sharing insights,  breakthroughs, and learnings from my enthralling side projects in the field. 
</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"></ul>
</div>

  </div>

</footer>
</body>

</html>
